{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-20T16:55:52.114899Z",
     "iopub.status.busy": "2020-12-20T16:55:52.114169Z",
     "iopub.status.idle": "2020-12-20T16:55:54.360177Z",
     "shell.execute_reply": "2020-12-20T16:55:54.359623Z"
    },
    "papermill": {
     "duration": 2.265298,
     "end_time": "2020-12-20T16:55:54.360306",
     "exception": false,
     "start_time": "2020-12-20T16:55:52.095008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.manifold import TSNE\n",
    "import gc\n",
    "from optuna.integration.lightgbm import LightGBMTunerCV\n",
    "#from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-20T16:55:54.412502Z",
     "iopub.status.busy": "2020-12-20T16:55:54.411458Z",
     "iopub.status.idle": "2020-12-20T16:55:54.414557Z",
     "shell.execute_reply": "2020-12-20T16:55:54.414975Z"
    },
    "papermill": {
     "duration": 0.04552,
     "end_time": "2020-12-20T16:55:54.415118",
     "exception": false,
     "start_time": "2020-12-20T16:55:54.369598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imputation(df):\n",
    "    for col in df:\n",
    "        if(df[col].dtype=='object'):\n",
    "            df[col].replace(np.nan,df[col].mode().iloc[0],inplace=True)\n",
    "        else:\n",
    "            df[col].replace(np.nan,df[col].mean(),inplace=True)\n",
    "    print(\"Imputaion Done\")\n",
    "    return df\n",
    "\n",
    "def label_encoder(df): #based on https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/?ref=rp\n",
    "    le = LabelEncoder()\n",
    "    le_count = 0\n",
    "    for col in df: \n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype(str)\n",
    "            #if len(list(df[col].unique())) <= 2:   #uncomment this line to encode columns with total unique values less than 3\n",
    "            le.fit(df[col])\n",
    "            df[col] = le.transform(df[col])\n",
    "            le_count += 1\n",
    "    print('%d columns were label encoded.' % le_count)\n",
    "\n",
    "def Remove_anomaly(name,lst,typ):\n",
    "    for var in lst:\n",
    "        temp_data = name[var]\n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        for val in temp_data:\n",
    "            if typ == 1:\n",
    "                if val<0:\n",
    "                    count +=1\n",
    "                    name.at[count1,var] = np.nan\n",
    "            else:\n",
    "                if val>0:\n",
    "                    count +=1\n",
    "                    name.at[count1,var] = np.nan\n",
    "            count1+=1\n",
    "        print('Total anomalies ='+str(count))   \n",
    "        #Plot_hist(temp_data,var)\n",
    "        return\n",
    "\n",
    "def clean_features(d_file,no_unique= 0,percentage= 100):\n",
    "    cat_cols = []\n",
    "    int_cols = []\n",
    "    \n",
    "    ln = len(d_file.columns)\n",
    "    #no_unique, number of unique values\n",
    "    #percentage, max percentage the no_unique can take\n",
    "    \n",
    "    for col in d_file:\n",
    "        k = (d_file[col].value_counts()/d_file[col].count())*100\n",
    "        if sum(list(k.head(no_unique)))<percentage:\n",
    "            if d_file[col].dtypes == \"object\":\n",
    "                cat_cols.append(col)\n",
    "            else: int_cols.append(col)\n",
    "                \n",
    "    #removing all features execpt the ones that have passed the above test\n",
    "    d_file = d_file.drop(train_file.columns.difference(cat_cols+int_cols),1)\n",
    "    \n",
    "    print(ln-len(d_file.columns),\"Features dropped\")\n",
    "    \n",
    "\n",
    "def treat_iqr(d_file):\n",
    "    count = 0\n",
    "    for col in d_file:\n",
    "        if col != 'TARGET':\n",
    "            skew_prev = d_file[col].skew()\n",
    "    \n",
    "            Q1 = d_file[col].quantile(0.25)\n",
    "            Q2 = d_file[col].quantile(0.75)\n",
    "            IQR = Q2-Q1\n",
    "        \n",
    "            Q3 = Q2-3*IQR\n",
    "            Q4 = Q3+3*IQR\n",
    "        \n",
    "            d_file[col] = np.where(d_file[col]<Q3,Q3,d_file[col])\n",
    "            d_file[col] = np.where(d_file[col]>Q4,Q4,d_file[col])\n",
    "        \n",
    "            skew_after = d_file[col].skew()\n",
    "        \n",
    "            if (skew_prev != skew_after):\n",
    "                count += 1\n",
    "            \n",
    "            print(col,\"Skew_prev:\",skew_prev,\"Skew_after:\",skew_after)\n",
    "    \n",
    "    print(\"Outliers changed in:\",count,\"columns\")\n",
    "\n",
    "def reduce_memory(df):\n",
    "    \"\"\"Reduce memory usage of a dataframe by setting data types. \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Initial df memory usage is {:.2f} MB for {} columns'\n",
    "          .format(start_mem, len(df.columns)))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # Can use unsigned int here too\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n",
    "    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n",
    "    original_columns = list(df.columns)\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and \"SK_ID\" not in col]\n",
    "    original_columns = [col for col in original_columns if col not in categorical_columns]\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    categorical_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, categorical_columns, original_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T16:55:54.441017Z",
     "iopub.status.busy": "2020-12-20T16:55:54.440403Z",
     "iopub.status.idle": "2020-12-20T16:56:31.170749Z",
     "shell.execute_reply": "2020-12-20T16:56:31.169708Z"
    },
    "papermill": {
     "duration": 36.747153,
     "end_time": "2020-12-20T16:56:31.170878",
     "exception": false,
     "start_time": "2020-12-20T16:55:54.423725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('../input/projectdf/DF_FE.csv',sep=',',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T16:56:31.198584Z",
     "iopub.status.busy": "2020-12-20T16:56:31.197655Z",
     "iopub.status.idle": "2020-12-20T16:57:30.668142Z",
     "shell.execute_reply": "2020-12-20T16:57:30.667560Z"
    },
    "papermill": {
     "duration": 59.48838,
     "end_time": "2020-12-20T16:57:30.668260",
     "exception": false,
     "start_time": "2020-12-20T16:56:31.179880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df memory usage is 1299.75 MB for 554 columns\n",
      "Final memory usage is: 306.17 MB - decreased by 76.4%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT_x</th>\n",
       "      <th>AMT_ANNUITY_x</th>\n",
       "      <th>AMT_GOODS_PRICE_x</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>WALLSMATERIAL_MODE_nan</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>EMERGENCYSTATE_MODE_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>33025.5</td>\n",
       "      <td>1125000.0</td>\n",
       "      <td>0.022797</td>\n",
       "      <td>51.875000</td>\n",
       "      <td>20.171875</td>\n",
       "      <td>6.441406</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>251280.0</td>\n",
       "      <td>13630.5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.022629</td>\n",
       "      <td>38.031250</td>\n",
       "      <td>3.814453</td>\n",
       "      <td>15.601562</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>544491.0</td>\n",
       "      <td>15916.5</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>54.281250</td>\n",
       "      <td>5.679688</td>\n",
       "      <td>5.808594</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>211500.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>26316.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>35.687500</td>\n",
       "      <td>6.035156</td>\n",
       "      <td>3.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>113760.0</td>\n",
       "      <td>8406.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.020706</td>\n",
       "      <td>50.343750</td>\n",
       "      <td>4.636719</td>\n",
       "      <td>22.671875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>835380.0</td>\n",
       "      <td>40320.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>35.812500</td>\n",
       "      <td>5.082031</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>56520.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>20.093750</td>\n",
       "      <td>23.671875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>301095.0</td>\n",
       "      <td>23773.5</td>\n",
       "      <td>279000.0</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>5.933594</td>\n",
       "      <td>0.325684</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.011703</td>\n",
       "      <td>22.453125</td>\n",
       "      <td>1.686523</td>\n",
       "      <td>22.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>21775.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>57.187500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.273438</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 554 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT_x  AMT_ANNUITY_x  \\\n",
       "0          0.0             0          360000.0     1125000.0        33025.5   \n",
       "1          0.0             0          112500.0      251280.0        13630.5   \n",
       "2          0.0             0          225000.0      544491.0        15916.5   \n",
       "3          0.0             2          211500.0      900000.0        26316.0   \n",
       "4          1.0             0           90000.0      113760.0         8406.0   \n",
       "...        ...           ...               ...           ...            ...   \n",
       "307506     NaN             1          202500.0      835380.0        40320.0   \n",
       "307507     NaN             0          450000.0     1800000.0        56520.0   \n",
       "307508     NaN             1          112500.0      301095.0        23773.5   \n",
       "307509     NaN             0           94500.0      180000.0         9000.0   \n",
       "307510     NaN             0           99000.0      675000.0        21775.5   \n",
       "\n",
       "        AMT_GOODS_PRICE_x  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0               1125000.0                    0.022797   51.875000   \n",
       "1                180000.0                    0.022629   38.031250   \n",
       "2                454500.0                    0.035797   54.281250   \n",
       "3                900000.0                    0.006207   35.687500   \n",
       "4                 90000.0                    0.020706   50.343750   \n",
       "...                   ...                         ...         ...   \n",
       "307506           675000.0                    0.035797   35.812500   \n",
       "307507          1800000.0                    0.002506   40.000000   \n",
       "307508           279000.0                    0.019104   42.750000   \n",
       "307509           180000.0                    0.011703   22.453125   \n",
       "307510           675000.0                    0.010498   57.187500   \n",
       "\n",
       "        DAYS_EMPLOYED  DAYS_REGISTRATION  ...  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0           20.171875           6.441406  ...                         0   \n",
       "1            3.814453          15.601562  ...                         0   \n",
       "2            5.679688           5.808594  ...                         0   \n",
       "3            6.035156           3.265625  ...                         0   \n",
       "4            4.636719          22.671875  ...                         0   \n",
       "...               ...                ...  ...                       ...   \n",
       "307506       5.082031          18.875000  ...                         0   \n",
       "307507      20.093750          23.671875  ...                         0   \n",
       "307508       5.933594           0.325684  ...                         0   \n",
       "307509       1.686523          22.437500  ...                         0   \n",
       "307510            NaN           7.273438  ...                         0   \n",
       "\n",
       "        WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                                   0                          0   \n",
       "1                                   0                          0   \n",
       "2                                   0                          0   \n",
       "3                                   0                          0   \n",
       "4                                   0                          0   \n",
       "...                               ...                        ...   \n",
       "307506                              0                          0   \n",
       "307507                              0                          0   \n",
       "307508                              0                          0   \n",
       "307509                              0                          0   \n",
       "307510                              0                          0   \n",
       "\n",
       "        WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              1                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "...                          ...                              ...   \n",
       "307506                         0                                0   \n",
       "307507                         0                                0   \n",
       "307508                         0                                0   \n",
       "307509                         0                                1   \n",
       "307510                         0                                0   \n",
       "\n",
       "        WALLSMATERIAL_MODE_Wooden  WALLSMATERIAL_MODE_nan  \\\n",
       "0                               0                       1   \n",
       "1                               0                       1   \n",
       "2                               0                       0   \n",
       "3                               0                       1   \n",
       "4                               0                       0   \n",
       "...                           ...                     ...   \n",
       "307506                          0                       1   \n",
       "307507                          0                       0   \n",
       "307508                          0                       1   \n",
       "307509                          0                       0   \n",
       "307510                          0                       1   \n",
       "\n",
       "        EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \\\n",
       "0                            0                        0   \n",
       "1                            0                        0   \n",
       "2                            1                        0   \n",
       "3                            0                        0   \n",
       "4                            1                        0   \n",
       "...                        ...                      ...   \n",
       "307506                       0                        0   \n",
       "307507                       1                        0   \n",
       "307508                       0                        0   \n",
       "307509                       1                        0   \n",
       "307510                       0                        0   \n",
       "\n",
       "        EMERGENCYSTATE_MODE_nan  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             0  \n",
       "3                             1  \n",
       "4                             0  \n",
       "...                         ...  \n",
       "307506                        1  \n",
       "307507                        0  \n",
       "307508                        1  \n",
       "307509                        0  \n",
       "307510                        1  \n",
       "\n",
       "[307511 rows x 554 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_memory(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T16:57:30.707094Z",
     "iopub.status.busy": "2020-12-20T16:57:30.706095Z",
     "iopub.status.idle": "2020-12-20T16:57:30.708789Z",
     "shell.execute_reply": "2020-12-20T16:57:30.709201Z"
    },
    "papermill": {
     "duration": 0.030127,
     "end_time": "2020-12-20T16:57:30.709360",
     "exception": false,
     "start_time": "2020-12-20T16:57:30.679233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        nseeds = 1\n",
    "        for s in range(nseeds):\n",
    "                   \n",
    "            # LightGBM parameters found by Bayesian optimization\n",
    "            #clf = LGBMClassifier(\n",
    "            #    nthread=4,\n",
    "            #    n_estimators=10000,\n",
    "            #   learning_rate=0.02,\n",
    "            #    num_leaves=34,\n",
    "            #    colsample_bytree=0.8,\n",
    "            #    subsample=0.87,\n",
    "            #    max_depth=8,\n",
    "            #    reg_alpha=0.041545473,\n",
    "            #    reg_lambda=0.0735294,\n",
    "            #    min_split_gain=0.0222415,\n",
    "            #    min_child_weight=40,\n",
    "            #   silent=-1,\n",
    "            #    verbose=-1, \n",
    "            #    seed=s,\n",
    "            #    random_state=s)\n",
    "            clf=LGBMRegressor(objective = 'binary',\n",
    "                                metric = 'binary_logloss',\n",
    "                                verbosity = -1,\n",
    "                                boosting_type = 'gbdt',\n",
    "                                feature_pre_filter = False,\n",
    "                                lambda_l1 = 7.497814244329271,\n",
    "                                lambda_l2 = 0.22692154687765595,\n",
    "                                num_leaves = 5,\n",
    "                                feature_fraction = 0.4,\n",
    "                                bagging_fraction = 1.0,\n",
    "                                bagging_freq = 0,\n",
    "                                min_child_samples = 5,\n",
    "                                learning_rate=0.01,\n",
    "                                seed = s,\n",
    "                                n_estimators = 100000                            \n",
    "                              )\n",
    "    \n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'auc', verbose= 200, early_stopping_rounds= 1000)\n",
    "    \n",
    "            \"\"\"\"\"oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "            y_pred = clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1]\n",
    "            sub_preds +=  pd.Series(y_pred).rank().values #/ folds.n_splits\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            fold_importance_df[\"seed\"] = s\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            \n",
    "            print('Fold %2d Seed %i AUC : %.6f' % (n_fold + 1, s, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        \"\"\"\n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T16:57:30.736795Z",
     "iopub.status.busy": "2020-12-20T16:57:30.735064Z",
     "iopub.status.idle": "2020-12-20T16:57:30.811941Z",
     "shell.execute_reply": "2020-12-20T16:57:30.811454Z"
    },
    "papermill": {
     "duration": 0.092289,
     "end_time": "2020-12-20T16:57:30.812052",
     "exception": false,
     "start_time": "2020-12-20T16:57:30.719763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T16:57:30.838363Z",
     "iopub.status.busy": "2020-12-20T16:57:30.837501Z",
     "iopub.status.idle": "2020-12-20T18:07:33.573826Z",
     "shell.execute_reply": "2020-12-20T18:07:33.574298Z"
    },
    "papermill": {
     "duration": 4202.751809,
     "end_time": "2020-12-20T18:07:33.574533",
     "exception": false,
     "start_time": "2020-12-20T16:57:30.822724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (199882, 554), test shape: (107629, 554)\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[200]\ttraining's auc: 0.744018\ttraining's binary_logloss: 0.258037\tvalid_1's auc: 0.737067\tvalid_1's binary_logloss: 0.259596\n",
      "[400]\ttraining's auc: 0.755391\ttraining's binary_logloss: 0.250992\tvalid_1's auc: 0.749417\tvalid_1's binary_logloss: 0.252727\n",
      "[600]\ttraining's auc: 0.764224\ttraining's binary_logloss: 0.247344\tvalid_1's auc: 0.757814\tvalid_1's binary_logloss: 0.249332\n",
      "[800]\ttraining's auc: 0.77045\ttraining's binary_logloss: 0.244948\tvalid_1's auc: 0.763067\tvalid_1's binary_logloss: 0.247306\n",
      "[1000]\ttraining's auc: 0.775008\ttraining's binary_logloss: 0.243171\tvalid_1's auc: 0.766616\tvalid_1's binary_logloss: 0.245912\n",
      "[1200]\ttraining's auc: 0.778516\ttraining's binary_logloss: 0.241798\tvalid_1's auc: 0.769109\tvalid_1's binary_logloss: 0.244924\n",
      "[1400]\ttraining's auc: 0.781448\ttraining's binary_logloss: 0.240681\tvalid_1's auc: 0.771082\tvalid_1's binary_logloss: 0.244154\n",
      "[1600]\ttraining's auc: 0.783889\ttraining's binary_logloss: 0.239751\tvalid_1's auc: 0.77263\tvalid_1's binary_logloss: 0.243564\n",
      "[1800]\ttraining's auc: 0.785898\ttraining's binary_logloss: 0.238961\tvalid_1's auc: 0.773738\tvalid_1's binary_logloss: 0.24311\n",
      "[2000]\ttraining's auc: 0.787679\ttraining's binary_logloss: 0.238266\tvalid_1's auc: 0.774607\tvalid_1's binary_logloss: 0.242742\n",
      "[2200]\ttraining's auc: 0.789269\ttraining's binary_logloss: 0.23766\tvalid_1's auc: 0.775329\tvalid_1's binary_logloss: 0.242448\n",
      "[2400]\ttraining's auc: 0.79077\ttraining's binary_logloss: 0.2371\tvalid_1's auc: 0.775963\tvalid_1's binary_logloss: 0.242194\n",
      "[2600]\ttraining's auc: 0.79217\ttraining's binary_logloss: 0.236584\tvalid_1's auc: 0.776541\tvalid_1's binary_logloss: 0.241966\n",
      "[2800]\ttraining's auc: 0.793514\ttraining's binary_logloss: 0.236096\tvalid_1's auc: 0.777049\tvalid_1's binary_logloss: 0.241775\n",
      "[3000]\ttraining's auc: 0.794822\ttraining's binary_logloss: 0.235632\tvalid_1's auc: 0.7775\tvalid_1's binary_logloss: 0.241602\n",
      "[3200]\ttraining's auc: 0.796028\ttraining's binary_logloss: 0.235191\tvalid_1's auc: 0.777903\tvalid_1's binary_logloss: 0.241447\n",
      "[3400]\ttraining's auc: 0.797218\ttraining's binary_logloss: 0.234764\tvalid_1's auc: 0.778213\tvalid_1's binary_logloss: 0.241324\n",
      "[3600]\ttraining's auc: 0.798318\ttraining's binary_logloss: 0.234367\tvalid_1's auc: 0.778546\tvalid_1's binary_logloss: 0.241201\n",
      "[3800]\ttraining's auc: 0.799415\ttraining's binary_logloss: 0.233969\tvalid_1's auc: 0.778837\tvalid_1's binary_logloss: 0.241091\n",
      "[4000]\ttraining's auc: 0.800512\ttraining's binary_logloss: 0.233575\tvalid_1's auc: 0.779144\tvalid_1's binary_logloss: 0.240986\n",
      "[4200]\ttraining's auc: 0.801573\ttraining's binary_logloss: 0.233191\tvalid_1's auc: 0.779391\tvalid_1's binary_logloss: 0.24089\n",
      "[4400]\ttraining's auc: 0.80263\ttraining's binary_logloss: 0.232812\tvalid_1's auc: 0.779631\tvalid_1's binary_logloss: 0.240799\n",
      "[4600]\ttraining's auc: 0.803661\ttraining's binary_logloss: 0.23244\tvalid_1's auc: 0.779852\tvalid_1's binary_logloss: 0.240719\n",
      "[4800]\ttraining's auc: 0.804709\ttraining's binary_logloss: 0.232064\tvalid_1's auc: 0.780039\tvalid_1's binary_logloss: 0.240643\n",
      "[5000]\ttraining's auc: 0.805732\ttraining's binary_logloss: 0.231692\tvalid_1's auc: 0.780222\tvalid_1's binary_logloss: 0.240563\n",
      "[5200]\ttraining's auc: 0.806774\ttraining's binary_logloss: 0.231311\tvalid_1's auc: 0.780525\tvalid_1's binary_logloss: 0.24046\n",
      "[5400]\ttraining's auc: 0.807783\ttraining's binary_logloss: 0.230938\tvalid_1's auc: 0.780745\tvalid_1's binary_logloss: 0.240368\n",
      "[5600]\ttraining's auc: 0.808727\ttraining's binary_logloss: 0.230591\tvalid_1's auc: 0.780907\tvalid_1's binary_logloss: 0.240308\n",
      "[5800]\ttraining's auc: 0.809697\ttraining's binary_logloss: 0.230238\tvalid_1's auc: 0.781149\tvalid_1's binary_logloss: 0.240224\n",
      "[6000]\ttraining's auc: 0.810626\ttraining's binary_logloss: 0.229898\tvalid_1's auc: 0.781349\tvalid_1's binary_logloss: 0.24016\n",
      "[6200]\ttraining's auc: 0.811572\ttraining's binary_logloss: 0.229557\tvalid_1's auc: 0.781522\tvalid_1's binary_logloss: 0.240101\n",
      "[6400]\ttraining's auc: 0.812476\ttraining's binary_logloss: 0.229226\tvalid_1's auc: 0.781725\tvalid_1's binary_logloss: 0.240027\n",
      "[6600]\ttraining's auc: 0.813385\ttraining's binary_logloss: 0.228903\tvalid_1's auc: 0.781879\tvalid_1's binary_logloss: 0.239978\n",
      "[6800]\ttraining's auc: 0.814266\ttraining's binary_logloss: 0.228576\tvalid_1's auc: 0.782008\tvalid_1's binary_logloss: 0.239925\n",
      "[7000]\ttraining's auc: 0.815115\ttraining's binary_logloss: 0.228264\tvalid_1's auc: 0.782119\tvalid_1's binary_logloss: 0.239878\n",
      "[7200]\ttraining's auc: 0.81597\ttraining's binary_logloss: 0.227948\tvalid_1's auc: 0.782209\tvalid_1's binary_logloss: 0.23984\n",
      "[7400]\ttraining's auc: 0.816844\ttraining's binary_logloss: 0.227635\tvalid_1's auc: 0.782266\tvalid_1's binary_logloss: 0.239817\n",
      "[7600]\ttraining's auc: 0.817669\ttraining's binary_logloss: 0.227327\tvalid_1's auc: 0.782318\tvalid_1's binary_logloss: 0.239794\n",
      "[7800]\ttraining's auc: 0.818482\ttraining's binary_logloss: 0.227026\tvalid_1's auc: 0.782398\tvalid_1's binary_logloss: 0.23976\n",
      "[8000]\ttraining's auc: 0.819279\ttraining's binary_logloss: 0.226725\tvalid_1's auc: 0.78245\tvalid_1's binary_logloss: 0.239735\n",
      "[8200]\ttraining's auc: 0.820097\ttraining's binary_logloss: 0.226412\tvalid_1's auc: 0.782555\tvalid_1's binary_logloss: 0.239694\n",
      "[8400]\ttraining's auc: 0.820898\ttraining's binary_logloss: 0.226109\tvalid_1's auc: 0.782693\tvalid_1's binary_logloss: 0.239647\n",
      "[8600]\ttraining's auc: 0.821675\ttraining's binary_logloss: 0.225816\tvalid_1's auc: 0.782751\tvalid_1's binary_logloss: 0.239632\n",
      "[8800]\ttraining's auc: 0.822505\ttraining's binary_logloss: 0.225507\tvalid_1's auc: 0.782855\tvalid_1's binary_logloss: 0.239592\n",
      "[9000]\ttraining's auc: 0.823293\ttraining's binary_logloss: 0.22521\tvalid_1's auc: 0.782921\tvalid_1's binary_logloss: 0.23957\n",
      "[9200]\ttraining's auc: 0.824058\ttraining's binary_logloss: 0.224919\tvalid_1's auc: 0.782976\tvalid_1's binary_logloss: 0.23955\n",
      "[9400]\ttraining's auc: 0.824817\ttraining's binary_logloss: 0.224629\tvalid_1's auc: 0.782987\tvalid_1's binary_logloss: 0.23954\n",
      "[9600]\ttraining's auc: 0.825597\ttraining's binary_logloss: 0.224338\tvalid_1's auc: 0.783034\tvalid_1's binary_logloss: 0.239525\n",
      "[9800]\ttraining's auc: 0.826335\ttraining's binary_logloss: 0.224057\tvalid_1's auc: 0.783085\tvalid_1's binary_logloss: 0.239507\n",
      "[10000]\ttraining's auc: 0.827076\ttraining's binary_logloss: 0.223773\tvalid_1's auc: 0.783117\tvalid_1's binary_logloss: 0.239503\n",
      "[10200]\ttraining's auc: 0.827812\ttraining's binary_logloss: 0.223494\tvalid_1's auc: 0.783172\tvalid_1's binary_logloss: 0.239482\n",
      "[10400]\ttraining's auc: 0.828533\ttraining's binary_logloss: 0.223217\tvalid_1's auc: 0.78321\tvalid_1's binary_logloss: 0.239469\n",
      "[10600]\ttraining's auc: 0.829249\ttraining's binary_logloss: 0.222938\tvalid_1's auc: 0.783273\tvalid_1's binary_logloss: 0.23945\n",
      "[10800]\ttraining's auc: 0.829968\ttraining's binary_logloss: 0.222658\tvalid_1's auc: 0.783281\tvalid_1's binary_logloss: 0.239444\n",
      "[11000]\ttraining's auc: 0.830685\ttraining's binary_logloss: 0.22238\tvalid_1's auc: 0.783323\tvalid_1's binary_logloss: 0.239431\n",
      "[11200]\ttraining's auc: 0.831394\ttraining's binary_logloss: 0.222109\tvalid_1's auc: 0.78335\tvalid_1's binary_logloss: 0.239422\n",
      "[11400]\ttraining's auc: 0.832073\ttraining's binary_logloss: 0.221842\tvalid_1's auc: 0.783365\tvalid_1's binary_logloss: 0.239413\n",
      "[11600]\ttraining's auc: 0.832736\ttraining's binary_logloss: 0.221575\tvalid_1's auc: 0.783359\tvalid_1's binary_logloss: 0.239411\n",
      "[11800]\ttraining's auc: 0.833418\ttraining's binary_logloss: 0.221308\tvalid_1's auc: 0.783393\tvalid_1's binary_logloss: 0.239399\n",
      "[12000]\ttraining's auc: 0.834088\ttraining's binary_logloss: 0.22105\tvalid_1's auc: 0.783418\tvalid_1's binary_logloss: 0.239387\n",
      "[12200]\ttraining's auc: 0.834752\ttraining's binary_logloss: 0.220785\tvalid_1's auc: 0.783504\tvalid_1's binary_logloss: 0.239359\n",
      "[12400]\ttraining's auc: 0.83542\ttraining's binary_logloss: 0.22052\tvalid_1's auc: 0.783507\tvalid_1's binary_logloss: 0.239353\n",
      "[12600]\ttraining's auc: 0.836078\ttraining's binary_logloss: 0.220252\tvalid_1's auc: 0.783515\tvalid_1's binary_logloss: 0.239349\n",
      "[12800]\ttraining's auc: 0.836719\ttraining's binary_logloss: 0.219994\tvalid_1's auc: 0.783539\tvalid_1's binary_logloss: 0.239345\n",
      "[13000]\ttraining's auc: 0.837365\ttraining's binary_logloss: 0.219735\tvalid_1's auc: 0.783516\tvalid_1's binary_logloss: 0.239353\n",
      "[13200]\ttraining's auc: 0.838014\ttraining's binary_logloss: 0.219477\tvalid_1's auc: 0.783481\tvalid_1's binary_logloss: 0.239365\n",
      "[13400]\ttraining's auc: 0.838663\ttraining's binary_logloss: 0.21922\tvalid_1's auc: 0.783494\tvalid_1's binary_logloss: 0.239362\n",
      "[13600]\ttraining's auc: 0.839321\ttraining's binary_logloss: 0.21896\tvalid_1's auc: 0.783483\tvalid_1's binary_logloss: 0.239364\n",
      "Early stopping, best iteration is:\n",
      "[12696]\ttraining's auc: 0.836395\ttraining's binary_logloss: 0.220126\tvalid_1's auc: 0.783549\tvalid_1's binary_logloss: 0.23934\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[200]\ttraining's auc: 0.746403\ttraining's binary_logloss: 0.255834\tvalid_1's auc: 0.733513\tvalid_1's binary_logloss: 0.267302\n",
      "[400]\ttraining's auc: 0.75753\ttraining's binary_logloss: 0.248642\tvalid_1's auc: 0.742817\tvalid_1's binary_logloss: 0.261048\n",
      "[600]\ttraining's auc: 0.766247\ttraining's binary_logloss: 0.244938\tvalid_1's auc: 0.750304\tvalid_1's binary_logloss: 0.258001\n",
      "[800]\ttraining's auc: 0.772128\ttraining's binary_logloss: 0.242559\tvalid_1's auc: 0.755174\tvalid_1's binary_logloss: 0.256138\n",
      "[1000]\ttraining's auc: 0.776523\ttraining's binary_logloss: 0.240826\tvalid_1's auc: 0.758858\tvalid_1's binary_logloss: 0.254809\n",
      "[1200]\ttraining's auc: 0.779861\ttraining's binary_logloss: 0.23949\tvalid_1's auc: 0.761599\tvalid_1's binary_logloss: 0.253814\n",
      "[1400]\ttraining's auc: 0.782469\ttraining's binary_logloss: 0.238446\tvalid_1's auc: 0.763674\tvalid_1's binary_logloss: 0.25307\n",
      "[1600]\ttraining's auc: 0.784818\ttraining's binary_logloss: 0.237564\tvalid_1's auc: 0.765453\tvalid_1's binary_logloss: 0.252466\n",
      "[1800]\ttraining's auc: 0.786953\ttraining's binary_logloss: 0.236787\tvalid_1's auc: 0.767078\tvalid_1's binary_logloss: 0.251925\n",
      "[2000]\ttraining's auc: 0.788723\ttraining's binary_logloss: 0.236123\tvalid_1's auc: 0.768295\tvalid_1's binary_logloss: 0.251516\n",
      "[2200]\ttraining's auc: 0.790352\ttraining's binary_logloss: 0.235528\tvalid_1's auc: 0.769363\tvalid_1's binary_logloss: 0.251171\n",
      "[2400]\ttraining's auc: 0.79178\ttraining's binary_logloss: 0.23499\tvalid_1's auc: 0.770156\tvalid_1's binary_logloss: 0.25091\n",
      "[2600]\ttraining's auc: 0.793102\ttraining's binary_logloss: 0.234491\tvalid_1's auc: 0.770761\tvalid_1's binary_logloss: 0.250705\n",
      "[2800]\ttraining's auc: 0.794407\ttraining's binary_logloss: 0.23402\tvalid_1's auc: 0.771337\tvalid_1's binary_logloss: 0.250528\n",
      "[3000]\ttraining's auc: 0.795667\ttraining's binary_logloss: 0.233571\tvalid_1's auc: 0.771799\tvalid_1's binary_logloss: 0.25038\n",
      "[3200]\ttraining's auc: 0.796815\ttraining's binary_logloss: 0.233147\tvalid_1's auc: 0.772181\tvalid_1's binary_logloss: 0.250251\n",
      "[3400]\ttraining's auc: 0.79795\ttraining's binary_logloss: 0.232737\tvalid_1's auc: 0.772601\tvalid_1's binary_logloss: 0.250114\n",
      "[3600]\ttraining's auc: 0.799098\ttraining's binary_logloss: 0.23233\tvalid_1's auc: 0.773002\tvalid_1's binary_logloss: 0.249985\n",
      "[3800]\ttraining's auc: 0.800221\ttraining's binary_logloss: 0.231928\tvalid_1's auc: 0.773405\tvalid_1's binary_logloss: 0.249864\n",
      "[4000]\ttraining's auc: 0.801329\ttraining's binary_logloss: 0.231532\tvalid_1's auc: 0.773743\tvalid_1's binary_logloss: 0.249753\n",
      "[4200]\ttraining's auc: 0.802411\ttraining's binary_logloss: 0.231153\tvalid_1's auc: 0.774077\tvalid_1's binary_logloss: 0.249654\n",
      "[4400]\ttraining's auc: 0.80345\ttraining's binary_logloss: 0.230783\tvalid_1's auc: 0.77435\tvalid_1's binary_logloss: 0.249575\n",
      "[4600]\ttraining's auc: 0.804488\ttraining's binary_logloss: 0.23041\tvalid_1's auc: 0.774666\tvalid_1's binary_logloss: 0.249483\n",
      "[4800]\ttraining's auc: 0.805512\ttraining's binary_logloss: 0.230036\tvalid_1's auc: 0.774981\tvalid_1's binary_logloss: 0.249386\n",
      "[5000]\ttraining's auc: 0.806531\ttraining's binary_logloss: 0.229675\tvalid_1's auc: 0.775229\tvalid_1's binary_logloss: 0.249309\n",
      "[5200]\ttraining's auc: 0.807553\ttraining's binary_logloss: 0.22931\tvalid_1's auc: 0.775502\tvalid_1's binary_logloss: 0.249219\n",
      "[5400]\ttraining's auc: 0.808533\ttraining's binary_logloss: 0.228958\tvalid_1's auc: 0.775718\tvalid_1's binary_logloss: 0.249144\n",
      "[5600]\ttraining's auc: 0.809479\ttraining's binary_logloss: 0.228614\tvalid_1's auc: 0.775919\tvalid_1's binary_logloss: 0.249073\n",
      "[5800]\ttraining's auc: 0.810426\ttraining's binary_logloss: 0.228265\tvalid_1's auc: 0.776184\tvalid_1's binary_logloss: 0.248991\n",
      "[6000]\ttraining's auc: 0.811344\ttraining's binary_logloss: 0.227931\tvalid_1's auc: 0.776366\tvalid_1's binary_logloss: 0.248924\n",
      "[6200]\ttraining's auc: 0.812279\ttraining's binary_logloss: 0.227596\tvalid_1's auc: 0.776573\tvalid_1's binary_logloss: 0.248851\n",
      "[6400]\ttraining's auc: 0.813138\ttraining's binary_logloss: 0.22728\tvalid_1's auc: 0.776691\tvalid_1's binary_logloss: 0.248817\n",
      "[6600]\ttraining's auc: 0.814023\ttraining's binary_logloss: 0.226955\tvalid_1's auc: 0.77685\tvalid_1's binary_logloss: 0.248767\n",
      "[6800]\ttraining's auc: 0.814887\ttraining's binary_logloss: 0.226634\tvalid_1's auc: 0.777027\tvalid_1's binary_logloss: 0.24871\n",
      "[7000]\ttraining's auc: 0.815748\ttraining's binary_logloss: 0.226318\tvalid_1's auc: 0.777166\tvalid_1's binary_logloss: 0.248667\n",
      "[7200]\ttraining's auc: 0.816601\ttraining's binary_logloss: 0.226004\tvalid_1's auc: 0.777274\tvalid_1's binary_logloss: 0.24863\n",
      "[7400]\ttraining's auc: 0.817459\ttraining's binary_logloss: 0.225685\tvalid_1's auc: 0.777376\tvalid_1's binary_logloss: 0.248593\n",
      "[7600]\ttraining's auc: 0.818283\ttraining's binary_logloss: 0.225381\tvalid_1's auc: 0.777488\tvalid_1's binary_logloss: 0.248552\n",
      "[7800]\ttraining's auc: 0.819094\ttraining's binary_logloss: 0.225073\tvalid_1's auc: 0.777617\tvalid_1's binary_logloss: 0.248512\n",
      "[8000]\ttraining's auc: 0.819889\ttraining's binary_logloss: 0.224774\tvalid_1's auc: 0.777712\tvalid_1's binary_logloss: 0.248483\n",
      "[8200]\ttraining's auc: 0.820683\ttraining's binary_logloss: 0.224474\tvalid_1's auc: 0.777805\tvalid_1's binary_logloss: 0.248452\n",
      "[8400]\ttraining's auc: 0.821443\ttraining's binary_logloss: 0.224177\tvalid_1's auc: 0.777869\tvalid_1's binary_logloss: 0.248426\n",
      "[8600]\ttraining's auc: 0.82226\ttraining's binary_logloss: 0.223875\tvalid_1's auc: 0.777961\tvalid_1's binary_logloss: 0.248393\n",
      "[8800]\ttraining's auc: 0.823033\ttraining's binary_logloss: 0.223584\tvalid_1's auc: 0.777989\tvalid_1's binary_logloss: 0.248379\n",
      "[9000]\ttraining's auc: 0.823792\ttraining's binary_logloss: 0.223292\tvalid_1's auc: 0.778059\tvalid_1's binary_logloss: 0.248351\n",
      "[9200]\ttraining's auc: 0.824552\ttraining's binary_logloss: 0.223003\tvalid_1's auc: 0.778108\tvalid_1's binary_logloss: 0.248335\n",
      "[9400]\ttraining's auc: 0.825319\ttraining's binary_logloss: 0.222717\tvalid_1's auc: 0.778152\tvalid_1's binary_logloss: 0.248315\n",
      "[9600]\ttraining's auc: 0.826068\ttraining's binary_logloss: 0.222433\tvalid_1's auc: 0.778201\tvalid_1's binary_logloss: 0.248296\n",
      "[9800]\ttraining's auc: 0.826805\ttraining's binary_logloss: 0.222153\tvalid_1's auc: 0.778271\tvalid_1's binary_logloss: 0.248273\n",
      "[10000]\ttraining's auc: 0.827544\ttraining's binary_logloss: 0.221867\tvalid_1's auc: 0.778339\tvalid_1's binary_logloss: 0.248251\n",
      "[10200]\ttraining's auc: 0.828289\ttraining's binary_logloss: 0.221584\tvalid_1's auc: 0.778318\tvalid_1's binary_logloss: 0.248256\n",
      "[10400]\ttraining's auc: 0.828996\ttraining's binary_logloss: 0.221308\tvalid_1's auc: 0.778377\tvalid_1's binary_logloss: 0.248235\n",
      "[10600]\ttraining's auc: 0.829699\ttraining's binary_logloss: 0.221035\tvalid_1's auc: 0.778443\tvalid_1's binary_logloss: 0.248205\n",
      "[10800]\ttraining's auc: 0.8304\ttraining's binary_logloss: 0.22076\tvalid_1's auc: 0.77846\tvalid_1's binary_logloss: 0.248194\n",
      "[11000]\ttraining's auc: 0.831089\ttraining's binary_logloss: 0.220493\tvalid_1's auc: 0.778494\tvalid_1's binary_logloss: 0.248184\n",
      "[11200]\ttraining's auc: 0.831806\ttraining's binary_logloss: 0.220217\tvalid_1's auc: 0.778535\tvalid_1's binary_logloss: 0.248166\n",
      "[11400]\ttraining's auc: 0.832492\ttraining's binary_logloss: 0.219949\tvalid_1's auc: 0.778533\tvalid_1's binary_logloss: 0.248162\n",
      "[11600]\ttraining's auc: 0.833169\ttraining's binary_logloss: 0.21969\tvalid_1's auc: 0.778532\tvalid_1's binary_logloss: 0.24816\n",
      "[11800]\ttraining's auc: 0.833824\ttraining's binary_logloss: 0.219426\tvalid_1's auc: 0.778554\tvalid_1's binary_logloss: 0.248154\n",
      "[12000]\ttraining's auc: 0.834506\ttraining's binary_logloss: 0.219155\tvalid_1's auc: 0.778574\tvalid_1's binary_logloss: 0.248146\n",
      "[12200]\ttraining's auc: 0.83516\ttraining's binary_logloss: 0.218891\tvalid_1's auc: 0.778591\tvalid_1's binary_logloss: 0.24814\n",
      "[12400]\ttraining's auc: 0.835839\ttraining's binary_logloss: 0.218629\tvalid_1's auc: 0.778566\tvalid_1's binary_logloss: 0.248148\n",
      "[12600]\ttraining's auc: 0.836514\ttraining's binary_logloss: 0.218362\tvalid_1's auc: 0.778592\tvalid_1's binary_logloss: 0.248135\n",
      "[12800]\ttraining's auc: 0.837174\ttraining's binary_logloss: 0.218099\tvalid_1's auc: 0.778619\tvalid_1's binary_logloss: 0.248128\n",
      "[13000]\ttraining's auc: 0.837828\ttraining's binary_logloss: 0.217843\tvalid_1's auc: 0.778653\tvalid_1's binary_logloss: 0.248116\n",
      "[13200]\ttraining's auc: 0.838487\ttraining's binary_logloss: 0.217581\tvalid_1's auc: 0.778644\tvalid_1's binary_logloss: 0.24812\n",
      "[13400]\ttraining's auc: 0.839108\ttraining's binary_logloss: 0.217332\tvalid_1's auc: 0.77867\tvalid_1's binary_logloss: 0.248113\n",
      "[13600]\ttraining's auc: 0.83976\ttraining's binary_logloss: 0.217073\tvalid_1's auc: 0.778616\tvalid_1's binary_logloss: 0.24813\n",
      "[13800]\ttraining's auc: 0.84042\ttraining's binary_logloss: 0.216815\tvalid_1's auc: 0.778616\tvalid_1's binary_logloss: 0.24813\n",
      "[14000]\ttraining's auc: 0.84106\ttraining's binary_logloss: 0.21656\tvalid_1's auc: 0.778614\tvalid_1's binary_logloss: 0.24814\n",
      "Early stopping, best iteration is:\n",
      "[13060]\ttraining's auc: 0.838039\ttraining's binary_logloss: 0.217764\tvalid_1's auc: 0.778678\tvalid_1's binary_logloss: 0.248109\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[200]\ttraining's auc: 0.742896\ttraining's binary_logloss: 0.259274\tvalid_1's auc: 0.743247\tvalid_1's binary_logloss: 0.254947\n",
      "[400]\ttraining's auc: 0.754319\ttraining's binary_logloss: 0.252316\tvalid_1's auc: 0.754153\tvalid_1's binary_logloss: 0.248063\n",
      "[600]\ttraining's auc: 0.763043\ttraining's binary_logloss: 0.248643\tvalid_1's auc: 0.761998\tvalid_1's binary_logloss: 0.244616\n",
      "[800]\ttraining's auc: 0.769189\ttraining's binary_logloss: 0.246278\tvalid_1's auc: 0.767061\tvalid_1's binary_logloss: 0.242538\n",
      "[1000]\ttraining's auc: 0.773727\ttraining's binary_logloss: 0.244534\tvalid_1's auc: 0.77071\tvalid_1's binary_logloss: 0.241052\n",
      "[1200]\ttraining's auc: 0.777097\ttraining's binary_logloss: 0.243203\tvalid_1's auc: 0.773539\tvalid_1's binary_logloss: 0.239911\n",
      "[1400]\ttraining's auc: 0.780125\ttraining's binary_logloss: 0.242087\tvalid_1's auc: 0.775741\tvalid_1's binary_logloss: 0.239025\n",
      "[1600]\ttraining's auc: 0.782609\ttraining's binary_logloss: 0.241151\tvalid_1's auc: 0.777505\tvalid_1's binary_logloss: 0.238318\n",
      "[1800]\ttraining's auc: 0.784622\ttraining's binary_logloss: 0.240374\tvalid_1's auc: 0.778889\tvalid_1's binary_logloss: 0.237778\n",
      "[2000]\ttraining's auc: 0.786395\ttraining's binary_logloss: 0.239697\tvalid_1's auc: 0.779831\tvalid_1's binary_logloss: 0.237379\n",
      "[2200]\ttraining's auc: 0.788033\ttraining's binary_logloss: 0.239079\tvalid_1's auc: 0.780736\tvalid_1's binary_logloss: 0.237017\n",
      "[2400]\ttraining's auc: 0.789523\ttraining's binary_logloss: 0.238516\tvalid_1's auc: 0.781432\tvalid_1's binary_logloss: 0.236744\n",
      "[2600]\ttraining's auc: 0.790939\ttraining's binary_logloss: 0.237996\tvalid_1's auc: 0.782018\tvalid_1's binary_logloss: 0.236519\n",
      "[2800]\ttraining's auc: 0.792327\ttraining's binary_logloss: 0.237497\tvalid_1's auc: 0.782581\tvalid_1's binary_logloss: 0.236321\n",
      "[3000]\ttraining's auc: 0.793654\ttraining's binary_logloss: 0.237013\tvalid_1's auc: 0.783079\tvalid_1's binary_logloss: 0.236141\n",
      "[3200]\ttraining's auc: 0.794908\ttraining's binary_logloss: 0.23656\tvalid_1's auc: 0.783543\tvalid_1's binary_logloss: 0.235979\n",
      "[3400]\ttraining's auc: 0.796115\ttraining's binary_logloss: 0.236126\tvalid_1's auc: 0.783884\tvalid_1's binary_logloss: 0.235848\n",
      "[3600]\ttraining's auc: 0.797282\ttraining's binary_logloss: 0.235707\tvalid_1's auc: 0.784201\tvalid_1's binary_logloss: 0.235732\n",
      "[3800]\ttraining's auc: 0.798443\ttraining's binary_logloss: 0.235296\tvalid_1's auc: 0.78448\tvalid_1's binary_logloss: 0.235637\n",
      "[4000]\ttraining's auc: 0.799575\ttraining's binary_logloss: 0.23489\tvalid_1's auc: 0.784729\tvalid_1's binary_logloss: 0.235556\n",
      "[4200]\ttraining's auc: 0.800679\ttraining's binary_logloss: 0.234488\tvalid_1's auc: 0.784996\tvalid_1's binary_logloss: 0.235462\n",
      "[4400]\ttraining's auc: 0.801736\ttraining's binary_logloss: 0.234107\tvalid_1's auc: 0.785228\tvalid_1's binary_logloss: 0.235378\n",
      "[4600]\ttraining's auc: 0.802774\ttraining's binary_logloss: 0.233731\tvalid_1's auc: 0.785413\tvalid_1's binary_logloss: 0.235309\n",
      "[4800]\ttraining's auc: 0.803776\ttraining's binary_logloss: 0.233361\tvalid_1's auc: 0.785688\tvalid_1's binary_logloss: 0.235214\n",
      "[5000]\ttraining's auc: 0.804813\ttraining's binary_logloss: 0.232988\tvalid_1's auc: 0.785944\tvalid_1's binary_logloss: 0.235133\n",
      "[5200]\ttraining's auc: 0.805785\ttraining's binary_logloss: 0.232626\tvalid_1's auc: 0.786154\tvalid_1's binary_logloss: 0.235062\n",
      "[5400]\ttraining's auc: 0.80674\ttraining's binary_logloss: 0.232276\tvalid_1's auc: 0.786323\tvalid_1's binary_logloss: 0.234996\n",
      "[5600]\ttraining's auc: 0.807705\ttraining's binary_logloss: 0.23192\tvalid_1's auc: 0.786552\tvalid_1's binary_logloss: 0.234926\n",
      "[5800]\ttraining's auc: 0.808638\ttraining's binary_logloss: 0.231579\tvalid_1's auc: 0.786676\tvalid_1's binary_logloss: 0.23488\n",
      "[6000]\ttraining's auc: 0.809499\ttraining's binary_logloss: 0.23126\tvalid_1's auc: 0.786735\tvalid_1's binary_logloss: 0.234855\n",
      "[6200]\ttraining's auc: 0.810365\ttraining's binary_logloss: 0.230934\tvalid_1's auc: 0.786816\tvalid_1's binary_logloss: 0.234824\n",
      "[6400]\ttraining's auc: 0.811253\ttraining's binary_logloss: 0.230602\tvalid_1's auc: 0.78694\tvalid_1's binary_logloss: 0.234778\n",
      "[6600]\ttraining's auc: 0.812142\ttraining's binary_logloss: 0.23027\tvalid_1's auc: 0.787091\tvalid_1's binary_logloss: 0.23472\n",
      "[6800]\ttraining's auc: 0.813009\ttraining's binary_logloss: 0.229949\tvalid_1's auc: 0.787159\tvalid_1's binary_logloss: 0.234691\n",
      "[7000]\ttraining's auc: 0.813876\ttraining's binary_logloss: 0.229631\tvalid_1's auc: 0.787251\tvalid_1's binary_logloss: 0.234667\n",
      "[7200]\ttraining's auc: 0.814724\ttraining's binary_logloss: 0.229309\tvalid_1's auc: 0.78737\tvalid_1's binary_logloss: 0.234625\n",
      "[7400]\ttraining's auc: 0.815567\ttraining's binary_logloss: 0.228989\tvalid_1's auc: 0.787418\tvalid_1's binary_logloss: 0.234605\n",
      "[7600]\ttraining's auc: 0.816391\ttraining's binary_logloss: 0.228679\tvalid_1's auc: 0.787546\tvalid_1's binary_logloss: 0.234571\n",
      "[7800]\ttraining's auc: 0.817207\ttraining's binary_logloss: 0.228378\tvalid_1's auc: 0.787603\tvalid_1's binary_logloss: 0.234547\n",
      "[8000]\ttraining's auc: 0.817982\ttraining's binary_logloss: 0.228079\tvalid_1's auc: 0.787671\tvalid_1's binary_logloss: 0.234535\n",
      "[8200]\ttraining's auc: 0.818766\ttraining's binary_logloss: 0.227778\tvalid_1's auc: 0.787774\tvalid_1's binary_logloss: 0.234509\n",
      "[8400]\ttraining's auc: 0.81954\ttraining's binary_logloss: 0.227483\tvalid_1's auc: 0.787854\tvalid_1's binary_logloss: 0.234489\n",
      "[8600]\ttraining's auc: 0.820283\ttraining's binary_logloss: 0.227196\tvalid_1's auc: 0.787898\tvalid_1's binary_logloss: 0.234481\n",
      "[8800]\ttraining's auc: 0.821049\ttraining's binary_logloss: 0.2269\tvalid_1's auc: 0.78795\tvalid_1's binary_logloss: 0.234463\n",
      "[9000]\ttraining's auc: 0.821825\ttraining's binary_logloss: 0.226609\tvalid_1's auc: 0.787967\tvalid_1's binary_logloss: 0.234456\n",
      "[9200]\ttraining's auc: 0.822564\ttraining's binary_logloss: 0.226322\tvalid_1's auc: 0.788\tvalid_1's binary_logloss: 0.234448\n",
      "[9400]\ttraining's auc: 0.823329\ttraining's binary_logloss: 0.22603\tvalid_1's auc: 0.788004\tvalid_1's binary_logloss: 0.234443\n",
      "[9600]\ttraining's auc: 0.824061\ttraining's binary_logloss: 0.225741\tvalid_1's auc: 0.788053\tvalid_1's binary_logloss: 0.234425\n",
      "[9800]\ttraining's auc: 0.824804\ttraining's binary_logloss: 0.225454\tvalid_1's auc: 0.788115\tvalid_1's binary_logloss: 0.234407\n",
      "[10000]\ttraining's auc: 0.825526\ttraining's binary_logloss: 0.22517\tvalid_1's auc: 0.788148\tvalid_1's binary_logloss: 0.234386\n",
      "[10200]\ttraining's auc: 0.826241\ttraining's binary_logloss: 0.22489\tvalid_1's auc: 0.788185\tvalid_1's binary_logloss: 0.234378\n",
      "[10400]\ttraining's auc: 0.826958\ttraining's binary_logloss: 0.224615\tvalid_1's auc: 0.788175\tvalid_1's binary_logloss: 0.234382\n",
      "[10600]\ttraining's auc: 0.827668\ttraining's binary_logloss: 0.224335\tvalid_1's auc: 0.78817\tvalid_1's binary_logloss: 0.234384\n",
      "[10800]\ttraining's auc: 0.828405\ttraining's binary_logloss: 0.224055\tvalid_1's auc: 0.788191\tvalid_1's binary_logloss: 0.234371\n",
      "[11000]\ttraining's auc: 0.829129\ttraining's binary_logloss: 0.223777\tvalid_1's auc: 0.788241\tvalid_1's binary_logloss: 0.234349\n",
      "[11200]\ttraining's auc: 0.829844\ttraining's binary_logloss: 0.223499\tvalid_1's auc: 0.788256\tvalid_1's binary_logloss: 0.234337\n",
      "[11400]\ttraining's auc: 0.830527\ttraining's binary_logloss: 0.22323\tvalid_1's auc: 0.788258\tvalid_1's binary_logloss: 0.234333\n",
      "[11600]\ttraining's auc: 0.831211\ttraining's binary_logloss: 0.222961\tvalid_1's auc: 0.788281\tvalid_1's binary_logloss: 0.234321\n",
      "[11800]\ttraining's auc: 0.831886\ttraining's binary_logloss: 0.222698\tvalid_1's auc: 0.788256\tvalid_1's binary_logloss: 0.234326\n",
      "[12000]\ttraining's auc: 0.832548\ttraining's binary_logloss: 0.222434\tvalid_1's auc: 0.788224\tvalid_1's binary_logloss: 0.234325\n",
      "[12200]\ttraining's auc: 0.833211\ttraining's binary_logloss: 0.222176\tvalid_1's auc: 0.788206\tvalid_1's binary_logloss: 0.234328\n",
      "[12400]\ttraining's auc: 0.833886\ttraining's binary_logloss: 0.221913\tvalid_1's auc: 0.788198\tvalid_1's binary_logloss: 0.234331\n",
      "[12600]\ttraining's auc: 0.834567\ttraining's binary_logloss: 0.22165\tvalid_1's auc: 0.788233\tvalid_1's binary_logloss: 0.234314\n",
      "Early stopping, best iteration is:\n",
      "[11617]\ttraining's auc: 0.831269\ttraining's binary_logloss: 0.222938\tvalid_1's auc: 0.788286\tvalid_1's binary_logloss: 0.234321\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[200]\ttraining's auc: 0.743807\ttraining's binary_logloss: 0.259362\tvalid_1's auc: 0.740397\tvalid_1's binary_logloss: 0.254313\n",
      "[400]\ttraining's auc: 0.754955\ttraining's binary_logloss: 0.252174\tvalid_1's auc: 0.751074\tvalid_1's binary_logloss: 0.247793\n",
      "[600]\ttraining's auc: 0.763837\ttraining's binary_logloss: 0.248453\tvalid_1's auc: 0.758968\tvalid_1's binary_logloss: 0.244614\n",
      "[800]\ttraining's auc: 0.769925\ttraining's binary_logloss: 0.246065\tvalid_1's auc: 0.76395\tvalid_1's binary_logloss: 0.242702\n",
      "[1000]\ttraining's auc: 0.77429\ttraining's binary_logloss: 0.244331\tvalid_1's auc: 0.767595\tvalid_1's binary_logloss: 0.241339\n",
      "[1200]\ttraining's auc: 0.777536\ttraining's binary_logloss: 0.24301\tvalid_1's auc: 0.770417\tvalid_1's binary_logloss: 0.240298\n",
      "[1400]\ttraining's auc: 0.780308\ttraining's binary_logloss: 0.241926\tvalid_1's auc: 0.772542\tvalid_1's binary_logloss: 0.239512\n",
      "[1600]\ttraining's auc: 0.782711\ttraining's binary_logloss: 0.241017\tvalid_1's auc: 0.774132\tvalid_1's binary_logloss: 0.238919\n",
      "[1800]\ttraining's auc: 0.784721\ttraining's binary_logloss: 0.240242\tvalid_1's auc: 0.775444\tvalid_1's binary_logloss: 0.238425\n",
      "[2000]\ttraining's auc: 0.78651\ttraining's binary_logloss: 0.239571\tvalid_1's auc: 0.776508\tvalid_1's binary_logloss: 0.238033\n",
      "[2200]\ttraining's auc: 0.788106\ttraining's binary_logloss: 0.23897\tvalid_1's auc: 0.777374\tvalid_1's binary_logloss: 0.237725\n",
      "[2400]\ttraining's auc: 0.78954\ttraining's binary_logloss: 0.238429\tvalid_1's auc: 0.778042\tvalid_1's binary_logloss: 0.237472\n",
      "[2600]\ttraining's auc: 0.790877\ttraining's binary_logloss: 0.237925\tvalid_1's auc: 0.778669\tvalid_1's binary_logloss: 0.237236\n",
      "[2800]\ttraining's auc: 0.792209\ttraining's binary_logloss: 0.237443\tvalid_1's auc: 0.779235\tvalid_1's binary_logloss: 0.237039\n",
      "[3000]\ttraining's auc: 0.793538\ttraining's binary_logloss: 0.23697\tvalid_1's auc: 0.779826\tvalid_1's binary_logloss: 0.236845\n",
      "[3200]\ttraining's auc: 0.794818\ttraining's binary_logloss: 0.23651\tvalid_1's auc: 0.780372\tvalid_1's binary_logloss: 0.236661\n",
      "[3400]\ttraining's auc: 0.796051\ttraining's binary_logloss: 0.236066\tvalid_1's auc: 0.780829\tvalid_1's binary_logloss: 0.236507\n",
      "[3600]\ttraining's auc: 0.797235\ttraining's binary_logloss: 0.235647\tvalid_1's auc: 0.781209\tvalid_1's binary_logloss: 0.236378\n",
      "[3800]\ttraining's auc: 0.798368\ttraining's binary_logloss: 0.235234\tvalid_1's auc: 0.781559\tvalid_1's binary_logloss: 0.236258\n",
      "[4000]\ttraining's auc: 0.799477\ttraining's binary_logloss: 0.234832\tvalid_1's auc: 0.781894\tvalid_1's binary_logloss: 0.236148\n",
      "[4200]\ttraining's auc: 0.800599\ttraining's binary_logloss: 0.234424\tvalid_1's auc: 0.782168\tvalid_1's binary_logloss: 0.236054\n",
      "[4400]\ttraining's auc: 0.801643\ttraining's binary_logloss: 0.234043\tvalid_1's auc: 0.78244\tvalid_1's binary_logloss: 0.235964\n",
      "[4600]\ttraining's auc: 0.802698\ttraining's binary_logloss: 0.233669\tvalid_1's auc: 0.782643\tvalid_1's binary_logloss: 0.235889\n",
      "[4800]\ttraining's auc: 0.803723\ttraining's binary_logloss: 0.233299\tvalid_1's auc: 0.78286\tvalid_1's binary_logloss: 0.235814\n",
      "[5000]\ttraining's auc: 0.804753\ttraining's binary_logloss: 0.232917\tvalid_1's auc: 0.7831\tvalid_1's binary_logloss: 0.235723\n",
      "[5200]\ttraining's auc: 0.80572\ttraining's binary_logloss: 0.232567\tvalid_1's auc: 0.783295\tvalid_1's binary_logloss: 0.235652\n",
      "[5400]\ttraining's auc: 0.806707\ttraining's binary_logloss: 0.232208\tvalid_1's auc: 0.783525\tvalid_1's binary_logloss: 0.23558\n",
      "[5600]\ttraining's auc: 0.807679\ttraining's binary_logloss: 0.231846\tvalid_1's auc: 0.783715\tvalid_1's binary_logloss: 0.235513\n",
      "[5800]\ttraining's auc: 0.808671\ttraining's binary_logloss: 0.231487\tvalid_1's auc: 0.783894\tvalid_1's binary_logloss: 0.235445\n",
      "[6000]\ttraining's auc: 0.809684\ttraining's binary_logloss: 0.231126\tvalid_1's auc: 0.784094\tvalid_1's binary_logloss: 0.235382\n",
      "[6200]\ttraining's auc: 0.810617\ttraining's binary_logloss: 0.230783\tvalid_1's auc: 0.784239\tvalid_1's binary_logloss: 0.235332\n",
      "[6400]\ttraining's auc: 0.811488\ttraining's binary_logloss: 0.230452\tvalid_1's auc: 0.784345\tvalid_1's binary_logloss: 0.235291\n",
      "[6600]\ttraining's auc: 0.812401\ttraining's binary_logloss: 0.230115\tvalid_1's auc: 0.784486\tvalid_1's binary_logloss: 0.235249\n",
      "[6800]\ttraining's auc: 0.813299\ttraining's binary_logloss: 0.229778\tvalid_1's auc: 0.784563\tvalid_1's binary_logloss: 0.23521\n",
      "[7000]\ttraining's auc: 0.814188\ttraining's binary_logloss: 0.229443\tvalid_1's auc: 0.784717\tvalid_1's binary_logloss: 0.235159\n",
      "[7200]\ttraining's auc: 0.815032\ttraining's binary_logloss: 0.229127\tvalid_1's auc: 0.784821\tvalid_1's binary_logloss: 0.235125\n",
      "[7400]\ttraining's auc: 0.815867\ttraining's binary_logloss: 0.228811\tvalid_1's auc: 0.784932\tvalid_1's binary_logloss: 0.235082\n",
      "[7600]\ttraining's auc: 0.816681\ttraining's binary_logloss: 0.228496\tvalid_1's auc: 0.785002\tvalid_1's binary_logloss: 0.235058\n",
      "[7800]\ttraining's auc: 0.817483\ttraining's binary_logloss: 0.22819\tvalid_1's auc: 0.785069\tvalid_1's binary_logloss: 0.235037\n",
      "[8000]\ttraining's auc: 0.818267\ttraining's binary_logloss: 0.227889\tvalid_1's auc: 0.785171\tvalid_1's binary_logloss: 0.235003\n",
      "[8200]\ttraining's auc: 0.81909\ttraining's binary_logloss: 0.227579\tvalid_1's auc: 0.78524\tvalid_1's binary_logloss: 0.234976\n",
      "[8400]\ttraining's auc: 0.819888\ttraining's binary_logloss: 0.22728\tvalid_1's auc: 0.785281\tvalid_1's binary_logloss: 0.234962\n",
      "[8600]\ttraining's auc: 0.820655\ttraining's binary_logloss: 0.226986\tvalid_1's auc: 0.785328\tvalid_1's binary_logloss: 0.234941\n",
      "[8800]\ttraining's auc: 0.821427\ttraining's binary_logloss: 0.226691\tvalid_1's auc: 0.785347\tvalid_1's binary_logloss: 0.234928\n",
      "[9000]\ttraining's auc: 0.822184\ttraining's binary_logloss: 0.226395\tvalid_1's auc: 0.785444\tvalid_1's binary_logloss: 0.234894\n",
      "[9200]\ttraining's auc: 0.822955\ttraining's binary_logloss: 0.226099\tvalid_1's auc: 0.785562\tvalid_1's binary_logloss: 0.234858\n",
      "[9400]\ttraining's auc: 0.823732\ttraining's binary_logloss: 0.225801\tvalid_1's auc: 0.785641\tvalid_1's binary_logloss: 0.234831\n",
      "[9600]\ttraining's auc: 0.824463\ttraining's binary_logloss: 0.225519\tvalid_1's auc: 0.785677\tvalid_1's binary_logloss: 0.23482\n",
      "[9800]\ttraining's auc: 0.825217\ttraining's binary_logloss: 0.225227\tvalid_1's auc: 0.785742\tvalid_1's binary_logloss: 0.234797\n",
      "[10000]\ttraining's auc: 0.825957\ttraining's binary_logloss: 0.224941\tvalid_1's auc: 0.785781\tvalid_1's binary_logloss: 0.23478\n",
      "[10200]\ttraining's auc: 0.826702\ttraining's binary_logloss: 0.224652\tvalid_1's auc: 0.785856\tvalid_1's binary_logloss: 0.234752\n",
      "[10400]\ttraining's auc: 0.82744\ttraining's binary_logloss: 0.224366\tvalid_1's auc: 0.785891\tvalid_1's binary_logloss: 0.234738\n",
      "[10600]\ttraining's auc: 0.828157\ttraining's binary_logloss: 0.224082\tvalid_1's auc: 0.785938\tvalid_1's binary_logloss: 0.234721\n",
      "[10800]\ttraining's auc: 0.828854\ttraining's binary_logloss: 0.223806\tvalid_1's auc: 0.785994\tvalid_1's binary_logloss: 0.234701\n",
      "[11000]\ttraining's auc: 0.829594\ttraining's binary_logloss: 0.22352\tvalid_1's auc: 0.78606\tvalid_1's binary_logloss: 0.234678\n",
      "[11200]\ttraining's auc: 0.830294\ttraining's binary_logloss: 0.223246\tvalid_1's auc: 0.786098\tvalid_1's binary_logloss: 0.234669\n",
      "[11400]\ttraining's auc: 0.831027\ttraining's binary_logloss: 0.22296\tvalid_1's auc: 0.786166\tvalid_1's binary_logloss: 0.234636\n",
      "[11600]\ttraining's auc: 0.831717\ttraining's binary_logloss: 0.222686\tvalid_1's auc: 0.786254\tvalid_1's binary_logloss: 0.23461\n",
      "[11800]\ttraining's auc: 0.832376\ttraining's binary_logloss: 0.222417\tvalid_1's auc: 0.78631\tvalid_1's binary_logloss: 0.234588\n",
      "[12000]\ttraining's auc: 0.833036\ttraining's binary_logloss: 0.222149\tvalid_1's auc: 0.786334\tvalid_1's binary_logloss: 0.234574\n",
      "[12200]\ttraining's auc: 0.833715\ttraining's binary_logloss: 0.221881\tvalid_1's auc: 0.786353\tvalid_1's binary_logloss: 0.234565\n",
      "[12400]\ttraining's auc: 0.834365\ttraining's binary_logloss: 0.221614\tvalid_1's auc: 0.786385\tvalid_1's binary_logloss: 0.234556\n",
      "[12600]\ttraining's auc: 0.835046\ttraining's binary_logloss: 0.221343\tvalid_1's auc: 0.786385\tvalid_1's binary_logloss: 0.23455\n",
      "[12800]\ttraining's auc: 0.835687\ttraining's binary_logloss: 0.221081\tvalid_1's auc: 0.786438\tvalid_1's binary_logloss: 0.234527\n",
      "[13000]\ttraining's auc: 0.836339\ttraining's binary_logloss: 0.22082\tvalid_1's auc: 0.786434\tvalid_1's binary_logloss: 0.234529\n",
      "[13200]\ttraining's auc: 0.837\ttraining's binary_logloss: 0.220555\tvalid_1's auc: 0.786485\tvalid_1's binary_logloss: 0.234511\n",
      "[13400]\ttraining's auc: 0.837644\ttraining's binary_logloss: 0.220291\tvalid_1's auc: 0.786529\tvalid_1's binary_logloss: 0.234492\n",
      "[13600]\ttraining's auc: 0.838286\ttraining's binary_logloss: 0.220029\tvalid_1's auc: 0.786556\tvalid_1's binary_logloss: 0.234483\n",
      "[13800]\ttraining's auc: 0.838907\ttraining's binary_logloss: 0.219773\tvalid_1's auc: 0.786569\tvalid_1's binary_logloss: 0.234482\n",
      "[14000]\ttraining's auc: 0.839538\ttraining's binary_logloss: 0.219515\tvalid_1's auc: 0.786586\tvalid_1's binary_logloss: 0.234471\n",
      "[14200]\ttraining's auc: 0.840159\ttraining's binary_logloss: 0.219257\tvalid_1's auc: 0.786555\tvalid_1's binary_logloss: 0.234477\n",
      "[14400]\ttraining's auc: 0.84079\ttraining's binary_logloss: 0.218999\tvalid_1's auc: 0.786564\tvalid_1's binary_logloss: 0.234469\n",
      "[14600]\ttraining's auc: 0.841422\ttraining's binary_logloss: 0.21874\tvalid_1's auc: 0.786533\tvalid_1's binary_logloss: 0.234477\n",
      "[14800]\ttraining's auc: 0.842052\ttraining's binary_logloss: 0.218487\tvalid_1's auc: 0.786581\tvalid_1's binary_logloss: 0.234465\n",
      "Early stopping, best iteration is:\n",
      "[13953]\ttraining's auc: 0.839382\ttraining's binary_logloss: 0.219579\tvalid_1's auc: 0.786604\tvalid_1's binary_logloss: 0.234469\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[200]\ttraining's auc: 0.744265\ttraining's binary_logloss: 0.258182\tvalid_1's auc: 0.741276\tvalid_1's binary_logloss: 0.258641\n",
      "[400]\ttraining's auc: 0.756068\ttraining's binary_logloss: 0.250959\tvalid_1's auc: 0.750455\tvalid_1's binary_logloss: 0.252054\n",
      "[600]\ttraining's auc: 0.764776\ttraining's binary_logloss: 0.247302\tvalid_1's auc: 0.7576\tvalid_1's binary_logloss: 0.248905\n",
      "[800]\ttraining's auc: 0.770828\ttraining's binary_logloss: 0.244922\tvalid_1's auc: 0.762564\tvalid_1's binary_logloss: 0.246912\n",
      "[1000]\ttraining's auc: 0.775246\ttraining's binary_logloss: 0.243193\tvalid_1's auc: 0.766153\tvalid_1's binary_logloss: 0.245495\n",
      "[1200]\ttraining's auc: 0.778665\ttraining's binary_logloss: 0.241862\tvalid_1's auc: 0.768771\tvalid_1's binary_logloss: 0.244474\n",
      "[1400]\ttraining's auc: 0.781317\ttraining's binary_logloss: 0.24079\tvalid_1's auc: 0.770598\tvalid_1's binary_logloss: 0.24374\n",
      "[1600]\ttraining's auc: 0.783478\ttraining's binary_logloss: 0.239913\tvalid_1's auc: 0.772029\tvalid_1's binary_logloss: 0.243161\n",
      "[1800]\ttraining's auc: 0.785359\ttraining's binary_logloss: 0.23916\tvalid_1's auc: 0.773277\tvalid_1's binary_logloss: 0.242689\n",
      "[2000]\ttraining's auc: 0.787122\ttraining's binary_logloss: 0.238486\tvalid_1's auc: 0.774337\tvalid_1's binary_logloss: 0.242312\n",
      "[2200]\ttraining's auc: 0.788799\ttraining's binary_logloss: 0.237872\tvalid_1's auc: 0.775449\tvalid_1's binary_logloss: 0.241955\n",
      "[2400]\ttraining's auc: 0.790327\ttraining's binary_logloss: 0.237316\tvalid_1's auc: 0.776336\tvalid_1's binary_logloss: 0.241671\n",
      "[2600]\ttraining's auc: 0.791798\ttraining's binary_logloss: 0.236796\tvalid_1's auc: 0.77704\tvalid_1's binary_logloss: 0.241445\n",
      "[2800]\ttraining's auc: 0.793167\ttraining's binary_logloss: 0.236304\tvalid_1's auc: 0.777707\tvalid_1's binary_logloss: 0.241228\n",
      "[3000]\ttraining's auc: 0.79449\ttraining's binary_logloss: 0.235835\tvalid_1's auc: 0.778299\tvalid_1's binary_logloss: 0.241038\n",
      "[3200]\ttraining's auc: 0.795716\ttraining's binary_logloss: 0.235387\tvalid_1's auc: 0.778719\tvalid_1's binary_logloss: 0.240894\n",
      "[3400]\ttraining's auc: 0.796934\ttraining's binary_logloss: 0.234952\tvalid_1's auc: 0.779157\tvalid_1's binary_logloss: 0.240745\n",
      "[3600]\ttraining's auc: 0.798112\ttraining's binary_logloss: 0.234527\tvalid_1's auc: 0.779575\tvalid_1's binary_logloss: 0.240609\n",
      "[3800]\ttraining's auc: 0.799235\ttraining's binary_logloss: 0.23412\tvalid_1's auc: 0.779981\tvalid_1's binary_logloss: 0.240481\n",
      "[4000]\ttraining's auc: 0.800301\ttraining's binary_logloss: 0.233731\tvalid_1's auc: 0.780275\tvalid_1's binary_logloss: 0.240373\n",
      "[4200]\ttraining's auc: 0.801438\ttraining's binary_logloss: 0.23333\tvalid_1's auc: 0.780649\tvalid_1's binary_logloss: 0.240243\n",
      "[4400]\ttraining's auc: 0.802529\ttraining's binary_logloss: 0.232945\tvalid_1's auc: 0.780909\tvalid_1's binary_logloss: 0.240152\n",
      "[4600]\ttraining's auc: 0.803541\ttraining's binary_logloss: 0.23258\tvalid_1's auc: 0.781135\tvalid_1's binary_logloss: 0.240072\n",
      "[4800]\ttraining's auc: 0.804523\ttraining's binary_logloss: 0.23222\tvalid_1's auc: 0.781337\tvalid_1's binary_logloss: 0.240004\n",
      "[5000]\ttraining's auc: 0.805525\ttraining's binary_logloss: 0.231859\tvalid_1's auc: 0.781575\tvalid_1's binary_logloss: 0.239916\n",
      "[5200]\ttraining's auc: 0.806538\ttraining's binary_logloss: 0.2315\tvalid_1's auc: 0.781805\tvalid_1's binary_logloss: 0.239843\n",
      "[5400]\ttraining's auc: 0.807511\ttraining's binary_logloss: 0.23115\tvalid_1's auc: 0.782041\tvalid_1's binary_logloss: 0.239769\n",
      "[5600]\ttraining's auc: 0.808459\ttraining's binary_logloss: 0.230811\tvalid_1's auc: 0.782249\tvalid_1's binary_logloss: 0.239703\n",
      "[5800]\ttraining's auc: 0.809374\ttraining's binary_logloss: 0.230479\tvalid_1's auc: 0.782461\tvalid_1's binary_logloss: 0.239637\n",
      "[6000]\ttraining's auc: 0.810282\ttraining's binary_logloss: 0.23015\tvalid_1's auc: 0.782658\tvalid_1's binary_logloss: 0.239579\n",
      "[6200]\ttraining's auc: 0.811181\ttraining's binary_logloss: 0.229828\tvalid_1's auc: 0.782846\tvalid_1's binary_logloss: 0.239524\n",
      "[6400]\ttraining's auc: 0.81208\ttraining's binary_logloss: 0.229506\tvalid_1's auc: 0.783012\tvalid_1's binary_logloss: 0.239475\n",
      "[6600]\ttraining's auc: 0.812956\ttraining's binary_logloss: 0.229184\tvalid_1's auc: 0.783166\tvalid_1's binary_logloss: 0.239422\n",
      "[6800]\ttraining's auc: 0.813845\ttraining's binary_logloss: 0.22885\tvalid_1's auc: 0.783387\tvalid_1's binary_logloss: 0.239342\n",
      "[7000]\ttraining's auc: 0.814699\ttraining's binary_logloss: 0.228539\tvalid_1's auc: 0.783531\tvalid_1's binary_logloss: 0.239288\n",
      "[7200]\ttraining's auc: 0.815535\ttraining's binary_logloss: 0.228228\tvalid_1's auc: 0.783633\tvalid_1's binary_logloss: 0.23925\n",
      "[7400]\ttraining's auc: 0.816401\ttraining's binary_logloss: 0.22791\tvalid_1's auc: 0.783795\tvalid_1's binary_logloss: 0.239197\n",
      "[7600]\ttraining's auc: 0.817189\ttraining's binary_logloss: 0.227611\tvalid_1's auc: 0.783903\tvalid_1's binary_logloss: 0.239157\n",
      "[7800]\ttraining's auc: 0.817976\ttraining's binary_logloss: 0.227316\tvalid_1's auc: 0.784037\tvalid_1's binary_logloss: 0.23911\n",
      "[8000]\ttraining's auc: 0.818776\ttraining's binary_logloss: 0.227021\tvalid_1's auc: 0.78415\tvalid_1's binary_logloss: 0.239067\n",
      "[8200]\ttraining's auc: 0.819601\ttraining's binary_logloss: 0.226717\tvalid_1's auc: 0.784239\tvalid_1's binary_logloss: 0.239038\n",
      "[8400]\ttraining's auc: 0.820378\ttraining's binary_logloss: 0.226425\tvalid_1's auc: 0.784357\tvalid_1's binary_logloss: 0.238993\n",
      "[8600]\ttraining's auc: 0.821155\ttraining's binary_logloss: 0.226133\tvalid_1's auc: 0.78441\tvalid_1's binary_logloss: 0.238971\n",
      "[8800]\ttraining's auc: 0.821942\ttraining's binary_logloss: 0.225846\tvalid_1's auc: 0.784476\tvalid_1's binary_logloss: 0.238942\n",
      "[9000]\ttraining's auc: 0.822704\ttraining's binary_logloss: 0.225556\tvalid_1's auc: 0.784601\tvalid_1's binary_logloss: 0.238903\n",
      "[9200]\ttraining's auc: 0.823448\ttraining's binary_logloss: 0.22527\tvalid_1's auc: 0.784734\tvalid_1's binary_logloss: 0.238862\n",
      "[9400]\ttraining's auc: 0.82419\ttraining's binary_logloss: 0.224985\tvalid_1's auc: 0.784753\tvalid_1's binary_logloss: 0.238841\n",
      "[9600]\ttraining's auc: 0.824923\ttraining's binary_logloss: 0.224702\tvalid_1's auc: 0.784878\tvalid_1's binary_logloss: 0.2388\n",
      "[9800]\ttraining's auc: 0.825659\ttraining's binary_logloss: 0.224421\tvalid_1's auc: 0.78494\tvalid_1's binary_logloss: 0.238773\n",
      "[10000]\ttraining's auc: 0.826403\ttraining's binary_logloss: 0.224135\tvalid_1's auc: 0.785007\tvalid_1's binary_logloss: 0.238747\n",
      "[10200]\ttraining's auc: 0.827127\ttraining's binary_logloss: 0.223863\tvalid_1's auc: 0.785079\tvalid_1's binary_logloss: 0.238726\n",
      "[10400]\ttraining's auc: 0.827848\ttraining's binary_logloss: 0.223587\tvalid_1's auc: 0.78515\tvalid_1's binary_logloss: 0.238704\n",
      "[10600]\ttraining's auc: 0.828583\ttraining's binary_logloss: 0.223307\tvalid_1's auc: 0.78523\tvalid_1's binary_logloss: 0.238683\n",
      "[10800]\ttraining's auc: 0.829316\ttraining's binary_logloss: 0.223028\tvalid_1's auc: 0.785273\tvalid_1's binary_logloss: 0.23867\n",
      "[11000]\ttraining's auc: 0.830011\ttraining's binary_logloss: 0.222754\tvalid_1's auc: 0.785351\tvalid_1's binary_logloss: 0.23864\n",
      "[11200]\ttraining's auc: 0.83073\ttraining's binary_logloss: 0.222486\tvalid_1's auc: 0.785415\tvalid_1's binary_logloss: 0.238619\n",
      "[11400]\ttraining's auc: 0.831432\ttraining's binary_logloss: 0.222215\tvalid_1's auc: 0.785472\tvalid_1's binary_logloss: 0.238601\n",
      "[11600]\ttraining's auc: 0.832125\ttraining's binary_logloss: 0.221947\tvalid_1's auc: 0.785553\tvalid_1's binary_logloss: 0.238583\n",
      "[11800]\ttraining's auc: 0.832815\ttraining's binary_logloss: 0.221673\tvalid_1's auc: 0.785573\tvalid_1's binary_logloss: 0.238576\n",
      "[12000]\ttraining's auc: 0.833491\ttraining's binary_logloss: 0.22141\tvalid_1's auc: 0.785587\tvalid_1's binary_logloss: 0.238563\n",
      "[12200]\ttraining's auc: 0.834168\ttraining's binary_logloss: 0.221148\tvalid_1's auc: 0.7856\tvalid_1's binary_logloss: 0.238556\n",
      "[12400]\ttraining's auc: 0.83482\ttraining's binary_logloss: 0.220882\tvalid_1's auc: 0.785646\tvalid_1's binary_logloss: 0.238537\n",
      "[12600]\ttraining's auc: 0.835504\ttraining's binary_logloss: 0.220618\tvalid_1's auc: 0.785661\tvalid_1's binary_logloss: 0.238528\n",
      "[12800]\ttraining's auc: 0.836164\ttraining's binary_logloss: 0.220354\tvalid_1's auc: 0.785729\tvalid_1's binary_logloss: 0.238505\n",
      "[13000]\ttraining's auc: 0.836813\ttraining's binary_logloss: 0.220096\tvalid_1's auc: 0.785802\tvalid_1's binary_logloss: 0.23848\n",
      "[13200]\ttraining's auc: 0.837466\ttraining's binary_logloss: 0.219839\tvalid_1's auc: 0.785834\tvalid_1's binary_logloss: 0.238465\n",
      "[13400]\ttraining's auc: 0.838092\ttraining's binary_logloss: 0.219586\tvalid_1's auc: 0.785848\tvalid_1's binary_logloss: 0.238458\n",
      "[13600]\ttraining's auc: 0.838722\ttraining's binary_logloss: 0.219335\tvalid_1's auc: 0.785895\tvalid_1's binary_logloss: 0.238443\n",
      "[13800]\ttraining's auc: 0.839372\ttraining's binary_logloss: 0.219079\tvalid_1's auc: 0.785903\tvalid_1's binary_logloss: 0.238439\n",
      "[14000]\ttraining's auc: 0.84001\ttraining's binary_logloss: 0.218819\tvalid_1's auc: 0.785935\tvalid_1's binary_logloss: 0.238428\n",
      "[14200]\ttraining's auc: 0.840614\ttraining's binary_logloss: 0.218571\tvalid_1's auc: 0.78596\tvalid_1's binary_logloss: 0.238419\n",
      "[14400]\ttraining's auc: 0.841242\ttraining's binary_logloss: 0.218319\tvalid_1's auc: 0.785947\tvalid_1's binary_logloss: 0.238418\n",
      "[14600]\ttraining's auc: 0.841869\ttraining's binary_logloss: 0.218069\tvalid_1's auc: 0.78595\tvalid_1's binary_logloss: 0.238417\n",
      "[14800]\ttraining's auc: 0.842468\ttraining's binary_logloss: 0.217822\tvalid_1's auc: 0.785973\tvalid_1's binary_logloss: 0.238402\n",
      "[15000]\ttraining's auc: 0.843066\ttraining's binary_logloss: 0.217578\tvalid_1's auc: 0.786016\tvalid_1's binary_logloss: 0.23839\n",
      "[15200]\ttraining's auc: 0.843694\ttraining's binary_logloss: 0.217329\tvalid_1's auc: 0.786072\tvalid_1's binary_logloss: 0.238371\n",
      "[15400]\ttraining's auc: 0.84429\ttraining's binary_logloss: 0.217087\tvalid_1's auc: 0.78607\tvalid_1's binary_logloss: 0.238365\n",
      "[15600]\ttraining's auc: 0.844884\ttraining's binary_logloss: 0.216847\tvalid_1's auc: 0.786077\tvalid_1's binary_logloss: 0.238361\n",
      "[15800]\ttraining's auc: 0.845482\ttraining's binary_logloss: 0.216607\tvalid_1's auc: 0.786028\tvalid_1's binary_logloss: 0.238376\n",
      "[16000]\ttraining's auc: 0.846061\ttraining's binary_logloss: 0.216369\tvalid_1's auc: 0.786036\tvalid_1's binary_logloss: 0.238374\n",
      "[16200]\ttraining's auc: 0.846644\ttraining's binary_logloss: 0.216127\tvalid_1's auc: 0.786094\tvalid_1's binary_logloss: 0.238349\n",
      "[16400]\ttraining's auc: 0.84722\ttraining's binary_logloss: 0.215887\tvalid_1's auc: 0.786134\tvalid_1's binary_logloss: 0.23834\n",
      "[16600]\ttraining's auc: 0.847798\ttraining's binary_logloss: 0.215652\tvalid_1's auc: 0.786134\tvalid_1's binary_logloss: 0.238343\n",
      "[16800]\ttraining's auc: 0.848388\ttraining's binary_logloss: 0.21541\tvalid_1's auc: 0.786133\tvalid_1's binary_logloss: 0.238345\n",
      "[17000]\ttraining's auc: 0.84896\ttraining's binary_logloss: 0.215175\tvalid_1's auc: 0.786087\tvalid_1's binary_logloss: 0.238351\n",
      "[17200]\ttraining's auc: 0.849521\ttraining's binary_logloss: 0.214943\tvalid_1's auc: 0.786061\tvalid_1's binary_logloss: 0.238351\n",
      "[17400]\ttraining's auc: 0.850074\ttraining's binary_logloss: 0.214706\tvalid_1's auc: 0.785993\tvalid_1's binary_logloss: 0.238365\n",
      "Early stopping, best iteration is:\n",
      "[16527]\ttraining's auc: 0.847596\ttraining's binary_logloss: 0.215736\tvalid_1's auc: 0.786147\tvalid_1's binary_logloss: 0.238339\n"
     ]
    }
   ],
   "source": [
    "feat_importance = kfold_lightgbm(df, num_folds= 5, stratified= False, debug= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:07:33.775213Z",
     "iopub.status.busy": "2020-12-20T18:07:33.774644Z",
     "iopub.status.idle": "2020-12-20T18:07:36.719193Z",
     "shell.execute_reply": "2020-12-20T18:07:36.718153Z"
    },
    "papermill": {
     "duration": 3.045594,
     "end_time": "2020-12-20T18:07:36.719383",
     "exception": false,
     "start_time": "2020-12-20T18:07:33.673789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_file Imported\n"
     ]
    }
   ],
   "source": [
    "Test_file = pd.read_csv('../input/iiitb2020-home-credit-default-risk/application_test.csv',sep = ',', low_memory = False)\n",
    "print(\"Test_file Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:07:36.948249Z",
     "iopub.status.busy": "2020-12-20T18:07:36.926704Z",
     "iopub.status.idle": "2020-12-20T18:07:37.133747Z",
     "shell.execute_reply": "2020-12-20T18:07:37.133074Z"
    },
    "papermill": {
     "duration": 0.313048,
     "end_time": "2020-12-20T18:07:37.133857",
     "exception": false,
     "start_time": "2020-12-20T18:07:36.820809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln = 199882\n",
    "sample = int(ln*3/10)\n",
    "ln1 = ln-sample\n",
    "\n",
    "X_train = df.iloc[:ln1,1:]\n",
    "y_train = df.iloc[:ln1,:1]\n",
    "\n",
    "X_test = df.iloc[ln1:ln1+sample,1:]\n",
    "y_test = df.iloc[ln1:ln1+sample,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:07:37.336744Z",
     "iopub.status.busy": "2020-12-20T18:07:37.336109Z",
     "iopub.status.idle": "2020-12-20T18:08:34.241807Z",
     "shell.execute_reply": "2020-12-20T18:08:34.241282Z"
    },
    "papermill": {
     "duration": 57.009209,
     "end_time": "2020-12-20T18:08:34.241923",
     "exception": false,
     "start_time": "2020-12-20T18:07:37.232714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 83.4571843320211\n",
      "Test Accuracy: 83.70225057377922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = feat_importance.predict(X_train)\n",
    "test_pred = feat_importance.predict(X_test)\n",
    "print(\"Train Accuracy:\",roc_auc_score(y_train,train_pred)*100)\n",
    "print(\"Test Accuracy:\",roc_auc_score(y_test,test_pred)*100)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:08:34.464486Z",
     "iopub.status.busy": "2020-12-20T18:08:34.463173Z",
     "iopub.status.idle": "2020-12-20T18:09:04.408986Z",
     "shell.execute_reply": "2020-12-20T18:09:04.408255Z"
    },
    "papermill": {
     "duration": 30.06679,
     "end_time": "2020-12-20T18:09:04.409141",
     "exception": false,
     "start_time": "2020-12-20T18:08:34.342351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln = 199882\n",
    "test_df = df.iloc[ln:,1:]\n",
    "#test_df = test_df.drop(\"TARGET\",axis=1)\n",
    "# Write submission file and plot feature importance\n",
    "sub_preds = feat_importance.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:09:04.656350Z",
     "iopub.status.busy": "2020-12-20T18:09:04.655615Z",
     "iopub.status.idle": "2020-12-20T18:09:04.658975Z",
     "shell.execute_reply": "2020-12-20T18:09:04.659380Z"
    },
    "papermill": {
     "duration": 0.10895,
     "end_time": "2020-12-20T18:09:04.659523",
     "exception": false,
     "start_time": "2020-12-20T18:09:04.550573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02444   , 0.09798999, 0.09297215, ..., 0.03462825, 0.07172402,\n",
       "       0.08201496])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:09:04.869418Z",
     "iopub.status.busy": "2020-12-20T18:09:04.868502Z",
     "iopub.status.idle": "2020-12-20T18:09:05.469926Z",
     "shell.execute_reply": "2020-12-20T18:09:05.469312Z"
    },
    "papermill": {
     "duration": 0.710201,
     "end_time": "2020-12-20T18:09:05.470045",
     "exception": false,
     "start_time": "2020-12-20T18:09:04.759844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID = Test_file.drop(Test_file.columns.difference([\"SK_ID_CURR\"]),1)\n",
    "\n",
    "submission = pd.DataFrame({'SK_ID_CURR': ID['SK_ID_CURR'], 'TARGET' : sub_preds})\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-20T18:09:05.680371Z",
     "iopub.status.busy": "2020-12-20T18:09:05.679278Z",
     "iopub.status.idle": "2020-12-20T18:09:05.695528Z",
     "shell.execute_reply": "2020-12-20T18:09:05.695924Z"
    },
    "papermill": {
     "duration": 0.125658,
     "end_time": "2020-12-20T18:09:05.696070",
     "exception": false,
     "start_time": "2020-12-20T18:09:05.570412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107629.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.080929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.092730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.024221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.047665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.098919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.898557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TARGET\n",
       "count  107629.000000\n",
       "mean        0.080929\n",
       "std         0.092730\n",
       "min         0.001121\n",
       "25%         0.024221\n",
       "50%         0.047665\n",
       "75%         0.098919\n",
       "max         0.898557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.123723,
     "end_time": "2020-12-20T18:09:05.919723",
     "exception": false,
     "start_time": "2020-12-20T18:09:05.796000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4398.739173,
   "end_time": "2020-12-20T18:09:06.145181",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-20T16:55:47.406008",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
